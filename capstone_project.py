# -*- coding: utf-8 -*-
"""Capstone Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XOSY7GCh34-Dn14TOfIMLfOx1_-YXqAm
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('CAR DETAILS.csv')
df.head()

df['fuel'].value_counts()

df.columns

df['km_driven'].value_counts()

df['seller_type'].value_counts()

df['name'].value_counts()

df['selling_price'].value_counts()

df['owner'].value_counts()

df['transmission'].value_counts()

df['year'].value_counts()

df.isnull().sum()

df.duplicated().sum()

plt.scatter(x=df['fuel'],y=df['km_driven'])
plt.title('FUEL ENGINE VS KM DRIVEN',color='blue')
plt.show()

"""## Conclusion
1) Diesel and Petrol engine equipped vehicles have covered much distance as compared to the other variants(CNG,LPG and Electric)
"""

sns.countplot(x=df['seller_type'])
plt.show()

"""## Conclusion
1) Individual sellers are bulk in number than dealer type sellers and Trust Mark dealers.
"""

sns.displot(x=df['transmission'],color='red')
plt.show()

"""## Conclusion
1) Manual transmission loaded vehicles outnumbers the Automatic transmission ones.
"""

sns.boxplot(x=df['year'],y=df['selling_price'])
plt.xticks(rotation=90)
plt.show()

"""## Conclusion
1)There is an increasing trend over the years with respect to selling price owing to the new and innovative features
"""

df.nunique()

df.head()

df.head()

df.drop(['year'],axis=1,inplace=True)

df.head()

"""# One Hot Encoding"""

df = pd.get_dummies(df,drop_first=True)

df.head()

df.corr()

x = df.iloc[:,1:]
y = df.iloc[:,0]

x.head()

y.head()

from sklearn.ensemble import ExtraTreesRegressor
model=ExtraTreesRegressor()
model.fit(x,y)

print(model.feature_importances_)

feat_importances = pd.Series(model.feature_importances_,index=x.columns)
feat_importances.nlargest(5).plot(kind='barh')
plt.show()

"""# Conclusion
Transmission manual and fuel diesel are the most significant features

# Train Test Splitting
"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)

x_train.shape

from sklearn.ensemble import RandomForestRegressor
rf_random=RandomForestRegressor()

import numpy as np
n_estimators=[int(x) for x in np.linspace(start=100,stop=1200,num=12)]
print(n_estimators)

max_features = ['auto','sqrt']
max_depth = [int(x) for x in np.linspace(5,30, num = 6)]
min_samples_split = [2,5,10,15,100]
min_samples_leaf = [1,2,5,10]

from sklearn.model_selection import RandomizedSearchCV

random_grid = {'n_estimators':n_estimators,
              'max_features': max_features,
              'max_depth': max_depth,
              'min_samples_split':min_samples_split,
              'min_samples_leaf':min_samples_leaf}
print(random_grid)

rf = RandomForestRegressor()

rf_random = RandomizedSearchCV(estimator = rf,param_distributions = random_grid,scoring='neg_mean_squared_error',n_iter=10,cv = 5, verbose=2,random_state=42,n_jobs=1)

rf_random.fit(x_train,y_train)

predictions=rf_random.predict(x_test)

predictions

sns.distplot(y_test-predictions)

plt.scatter(y_test,predictions)

import pickle
file = open('random_forest_regression_model.pkl','wb')
pickle.dump(rf_random,file)











